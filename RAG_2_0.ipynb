{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-qdoBCcL3qWc"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-community\n",
        "! pip install chromadb\n",
        "! pip install pypdf\n",
        "! pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedder"
      ],
      "metadata": {
        "id": "FqxTIFRO4y63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os"
      ],
      "metadata": {
        "id": "AXWmOaJP37su"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r chroma_db_nccn"
      ],
      "metadata": {
        "id": "ep9M-Fbz-9bA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -a input_files\n",
        "! rm -r input_files/.ipynb_checkpoints/\n",
        "! ls -a input_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c209SGB6Uhr",
        "outputId": "1fb1901b-4ade-42b2-d209-d565d169e4c3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  Resume.pdf\n",
            "rm: cannot remove 'input_files/.ipynb_checkpoints/': No such file or directory\n",
            ".  ..  Resume.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedder:\n",
        "  def __init__(self, files_path, db_name, refresh_db=False):\n",
        "    self.files_path = files_path\n",
        "    self.db_name    = db_name\n",
        "    self.docs       = []\n",
        "    self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    self.embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device' : 'cpu'})\n",
        "    if refresh_db: self._load_files()\n",
        "  def _load_files(self):\n",
        "    file_list = os.listdir(self.files_path)\n",
        "    for f in file_list: self.docs.extend(PyPDFLoader(self.files_path + f).load())\n",
        "    docs = self.text_splitter.split_documents(self.docs)\n",
        "    vectorstore = Chroma.from_documents(docs, self.embedding_function, persist_directory=self.db_name)"
      ],
      "metadata": {
        "id": "JGHB7azK4csM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = Embedder(\"./input_files/\", './chroma_db_nccn', True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7J8QsDy5fdu",
        "outputId": "a8c321cf-6fc9-479c-8b47-90bc9d9ff50b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-79d0177558d3>:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  self.embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device' : 'cpu'})\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG"
      ],
      "metadata": {
        "id": "8bLNmrBr7iA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "IWT7F0fP5gmd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GEMINI_API_KEY = \"\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "zhmj5apb7mZF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGHandler:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device' : 'cpu'})\n",
        "    self.vector_db = Chroma(persist_directory='./chroma_db_nccn', embedding_function=embedding_function)\n",
        "  def _generate_rag_prompt(self, query, context):\n",
        "    escaped = context.replace(\"'\", \"\").replace('\"', '').replace(\"\\n\", \" \")\n",
        "    prompt = (f\"\"\"\n",
        "    You are a helpful and informative bot that answers questions using text from reference context included below. \\\n",
        "    Be sure to respond in a complete sentence, being comprenhensive, including all relevant background information. \\\n",
        "    However, you are talinkg to a non-technical audience, so be sure to break down complicated concepts and \\\n",
        "    strike friendly and conversational tone. \\\n",
        "    If the context is irrelevant to the answer, you may ignore it.\n",
        "\n",
        "    Each context information will have some metadata at the end of the object, \\\n",
        "    please add the references of where can the user find this information, based \\\n",
        "    on the metadata.\n",
        "\n",
        "    USER QUESTION: '{query}'\n",
        "    CONTEXT: '{context}'\n",
        "\n",
        "    ANSWER:\n",
        "    \"\"\")\n",
        "    return prompt\n",
        "  def _get_relevant_context_from_db(self, query):\n",
        "    context = \"\"\n",
        "    search_results = self.vector_db.similarity_search(query, k=6)\n",
        "    for result in search_results:\n",
        "      context += result.page_content + \"\\n\"\n",
        "      context += f\"{result.metadata}\" + \"\\n\"\n",
        "      print(f\"{result.metadata}\")\n",
        "    return context\n",
        "  def _generate_answer(self, prompt):\n",
        "    answer = self.model.generate_content(prompt)\n",
        "    return answer.text\n",
        "  def query(self, query):\n",
        "    context = self._get_relevant_context_from_db(query)\n",
        "    prompt  = self._generate_rag_prompt(query, context)\n",
        "    answer  = self._generate_answer(prompt)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "0WiKucWC70Cy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_handler = RAGHandler(model)"
      ],
      "metadata": {
        "id": "n-b111dH8PIL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = rag_handler.query(\"What's the price to be charged for the email service?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "lurlIn8J8S5a",
        "outputId": "5c0de1c4-73a4-4cb8-dad1-cf12d0d244e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page': 34, 'source': './input_files/srs_doc.pdf'}\n",
            "{'page': 35, 'source': './input_files/srs_doc.pdf'}\n",
            "{'page': 29, 'source': './input_files/srs_doc.pdf'}\n",
            "{'page': 35, 'source': './input_files/srs_doc.pdf'}\n",
            "{'page': 14, 'source': './input_files/srs_doc.pdf'}\n",
            "{'page': 24, 'source': './input_files/srs_doc.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0qrfG4S8g10",
        "outputId": "e2be68af-b775-4d6a-ace8-e1b76af7229a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost of sending emails through a provider like SendGrid or Mailgun is estimated to be around $15 USD. This is mentioned in the section about \"Email Services\" in the document. \n",
            " \n",
            "   [Source: './input_files/srs_doc.pdf', page 35] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKpkeWKF8mzm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}